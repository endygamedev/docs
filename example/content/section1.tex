% TODO: Отступы до и после формул, нужно это закинуть в `spbseu.cls`
\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{0pt}


\section{Метод динамического программирования}

\subsection{Общая постановка задачи динамического программирования}

\indent Основоположником динамического программирования можно считать русского математика А. А. Маркова. Его исследовательские работы были продолжены в 1940-х годах американским математиком А. Вальдом, одним из основателей исследовательского анализа.

Однако наиболее полно и систематизировано сформулировать основные принципы оптимального управления многошаговыми процессами впервые удалось американскому математику Р. Беллману. Задачи управления запасами были первыми задачами, которые решались этим методом.

Динамическое программирование является разделом математической науки, в основе которой лежит изучение экстремальных задач управления (методы вычислительной математики, которые применяются для поиска экстремумов функций), планирование и разработка методов их решения, в котором процесс принятия решения разбивается на отдельные этапы. Также можно сказать, что динамическое программирование -- это способ решения сложных задач путём разбиения их на более простые подзадачи. Он применим к задачам с оптимальной подструктурой, выглядящим как набор перекрывающихся подзадач, сложность которых чуть меньше исходной.

В общей постановке задачу динамического программирования можно сформулировать следующим образом. Управляемая физическая система $S$, характеризуется определённым набором параметров. Требуется построить оптимальное решение $u^*$, на множестве допустимых решений, переводящее систему из начального состояния $x_0$ в конечное состояние $x_n$, обеспечив целевой функции нужный экстремум.

Алгоритмы динамического программирования используются для поиска решения не сразу для всей сложной задачи, а для поиска оптимального решения для нескольких более простых задач аналогичного содержания, на которые распадается исходная задача. Также данные алгоритмы могут применяться для подсчёта количества этих решений.

То есть в динамическом программировании задача разделяется на подзадачи, и решения этих подзадач объединяются вместе для достижения общего решения основной задачи.

Подзадачи могут быть рекурсивно вложены в более крупные задачи, тогда методы динамического программирования применимы, и существует связь между значением более крупной проблемы и значениями подзадач. В литературе такое соотношение называется уравнением Беллмана.

При использовании алгоритмического подхода <<разделяй и властвуй>>, подзадача может быть решена несколько раз. Динамическое программирование решает каждую из этих подзадач только один раз, тем самым уменьшив количество вычислений, а затем сохраняет результат, избегая повторного вычисления на более позднем этапе, когда требуется решение для этой подзадачи.

Динамическое программирование используется для решения задач оптимизации (например, поиск кратчайшего пути), где может существовать множество решений, но интерес представляет только поиск оптимального решения.

Задачи должны иметь свойства перекрывающихся подзадач. Иными словами, решаемая задача может быть разбита на подзадачи, которые многократно используется, причём рекурсивный алгоритм решает одну и ту же подзадачу много раз, а не создаёт новую подзадачу. Например, числа Фибоначчи. В конечном итоге, оптимальное решение может быть построено из оптимальных решений подзадач.

Следует отметить, что во многих случаях алгоритмы перебора могут работать быстрее, чем алгоритмы динамического программирования, но они не гарантируют оптимальное решение задачи.

\subsection{Уравнение Беллмана}

\indent Согласно Беллману, основной принцип оптимальности управления многошаговыми процессами может быть словесно выражен следующим образом: <<Оптимальное поведение обладает тем свойством, что, каковы бы ни были исходное состояние и первоначальное решение, последующие решения должны составлять оптимальное поведение относительно состояния, получающегося в результате первоначального решения>>. Иными словами, любой участок оптимальной траектории, в том числе и завершающий, также являются оптимальным, а ошибки в управлении, приводящие к отклонениям от оптимальной траектории, впоследствии не могут быть исправлены.

Рассмотрим функции $B_0(x_0), B_1(x_1), \hdots, B_n(x_n)$. Функции $B_i(x_i), i = 0,1, \hdots, n$ представляют собой максимальные значения сумм частных целевых функций $z_{i+1}(x_i, u_{i+1}) + \hdots +z_n(x_{n−1}, u_n)$, вычисляемые по всем допустимым <<укороченным>> наборам управлений $(u_{i+1}, \hdots,u_n)$. Иными словами, $B_i(x_i)$ -- условно-оптимальное значение целевой функции при переводе системы из состояния $x_i$ после шага с номером $i$ в конечное состояние $x_n$; условность оптимального значения состоит в том, что оно относится не ко всему процессу, а к его заключительной части, и зависит от выбора состояния $x_i$, являющегося начальным для «укороченного» процесса. Тем самым функции $B_i(x_i)$, называются функциями Беллмана, характеризуют экстремальные свойства управляемой системы $S$ на последних шагах процесса. При этом имеет место соотношение:
\begin{equation}
    B_n(x_n) = 0
\end{equation}

Это выражение справедливо, так как состояние $x_n$ уже является конечным, дальнейших изменений состояний системы не происходит, и соответствующий экономический эффект равен 0.

Принцип оптимальности Беллмана, лежащий в основе метода динамического программирования решений рассматриваемых задач, выражается следующим основным функциональным уравнением:
\begin{equation}
    B_{i-1}(x_{i-1}) = \max_{u_i}\{z_i(x_{i-1}, u_i) + B_i(x_i) \; | \; x_i = f_i(x_{i-1}, u_i)\}
\end{equation}
в котором индекс $i$ изменяется по номерам всех шагов процесса в обратном порядке: $i = n, n-1, \hdots , 2, 1$;

По своей структуре функциональное уравнение Беллмана является рекуррентным. Это означается, что в последовательности функций $B_0(x_0), B_1(x_1),$ $\hdots, B_n(x_n)$ каждая предшествующая выражается через последующую.

Уравнение Беллмана было впервые применено к теории управления техническими системами и другим темам прикладной математики, а затем стало важным инструментом экономической теории.

Чтобы понять функциональное уравнение Беллмана, необходимо понять несколько основных понятий. Во-первых, любая задача оптимизации имеет какую-то цель: минимизация времени в пути, минимизация затрат, максимизация прибыли и т. д. Математическая функция, которая описывает эту задачу, называется целевой функцией.

Динамическое программирование разбивает задачу многопериодного планирования на более простые этапы в разные моменты времени. Следовательно, необходимо отслеживать, как ситуация с решениями меняется со временем. Информация о текущей ситуации, которая необходима для принятия правильного решения, называется <<состоянием>>. Например, чтобы решить, сколько потреблять и тратить в каждый момент времени, люди должны знать (среди прочего) своё первоначальное богатство. Следовательно, богатство будет одной из их переменного состояния, но, вероятно, будут и другие.

Переменные, выбранные в любой данный момент времени, часто называю контрольными переменными. Например, учитывая их текущее состояние, люди могут решить, сколько потреблять сейчас. Выбор управляющих переменных теперь может быть эквивалентен выбору следующего состояния; в более общем случае на следующее состояние влияют другие факторы, помимо текущего контроля. Например, в простейшем случае сегодняшнее богатство и потребление могут точно определять завтрашнее богатство хотя, как правило, другие факторы также влияют на завтрашнее богатство.

Подход динамического программирования описывает оптимальный план, находя правило, которое сообщает, какими должны быть элементы управления, учитывая любое возможное значение состояния. Например, потребление зависит только от богатства, мы бы искали правило потребление как функцию богатства. Такое правило, определяющее элементы управления как функцию, называется функцией политики.

Наконец, по определению, оптимальным правилом принятия решения является то, которое достигает наилучшего возможного значения цели. Наилучшее возможное значение цели, записанное как функция состояния, называется функцией значения.

Ричард Беллман показал, что задача динамической оптимизации в дискретном времени может быть сформулирована в рекурсивной пошаговой форме, известной как обратная индукция, записав взаимосвязь между функцией значения в одном периоде и функцией значения в следующем периоде.

Существуют условия, которым должна удовлетворять общая задача оптимизации, чтобы её можно было описать методом динамического программирования:
